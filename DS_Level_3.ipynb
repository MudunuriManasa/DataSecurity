{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwsE7LyOmwZ9",
        "outputId": "2cd871de-2788-4c48-fd89-3511cda70fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Epoch 1/10\n",
            "Malicious clients detected: []\n",
            "Test Accuracy after round 1: 93.18%\n",
            "Global Epoch 2/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 2: 96.00%\n",
            "Global Epoch 3/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 3: 96.65%\n",
            "Global Epoch 4/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 4: 96.96%\n",
            "Global Epoch 5/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 5: 97.33%\n",
            "Global Epoch 6/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 6: 97.66%\n",
            "Global Epoch 7/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 7: 97.76%\n",
            "Global Epoch 8/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 8: 97.77%\n",
            "Global Epoch 9/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 9: 97.85%\n",
            "Global Epoch 10/10\n",
            "Malicious clients detected: [7]\n",
            "Test Accuracy after round 10: 97.75%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from scipy.fft import fft2, fftshift\n",
        "from skimage.filters import sobel\n",
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "# Define the CNN architecture\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Load data (each client will load its own data in a real FL scenario)\n",
        "def load_data(transform, datasets='MNIST'):\n",
        "    if datasets.upper() == 'MNIST':\n",
        "        train_dataset = torchvision.datasets.MNIST(\n",
        "            root=\"./data/mnist\", train=True, download=True, transform=transform)\n",
        "        test_dataset = torchvision.datasets.MNIST(\n",
        "            root=\"./data/mnist\", train=False, download=True, transform=transform)\n",
        "    else:\n",
        "        train_dataset = torchvision.datasets.CIFAR10(\n",
        "            root=\"./data/cifar-10-python\", train=True, download=True, transform=transform)\n",
        "        test_dataset = torchvision.datasets.CIFAR10(\n",
        "            root=\"./data/cifar-10-python\", train=False, download=True, transform=transform)\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "\n",
        "# Partition dataset for federated learning\n",
        "def partition_dataset(dataset, n_clients):\n",
        "    split_size = len(dataset) // n_clients\n",
        "    return random_split(dataset, [split_size] * n_clients)\n",
        "\n",
        "\n",
        "# Detection Functions\n",
        "def detect_checkerboard_or_adversarial_patterns(images):\n",
        "    flagged_indices = []\n",
        "    for idx, image in enumerate(images):\n",
        "        image_np = image.numpy()[0, :, :]\n",
        "        freq = np.abs(fftshift(fft2(image_np)))\n",
        "        freq_mean, freq_std = freq.mean(), freq.std()\n",
        "        edges = sobel(image_np)\n",
        "        edge_mean = edges.mean()\n",
        "        if freq_mean > 50 and freq_std > 30 and edge_mean > 0.1:\n",
        "            flagged_indices.append(idx)\n",
        "    return flagged_indices\n",
        "\n",
        "\n",
        "def detect_poisoned_labels(dataset):\n",
        "    labels = [label for _, label in dataset]\n",
        "    clustering = DBSCAN(eps=1, min_samples=5).fit(np.array(labels).reshape(-1, 1))\n",
        "    poisoned_indices = [\n",
        "        idx for idx, label in enumerate(labels) if clustering.labels_[idx] == -1\n",
        "    ]\n",
        "    return poisoned_indices\n",
        "\n",
        "\n",
        "def detect_noisy_inputs(images):\n",
        "    flagged_indices = []\n",
        "    for idx, image in enumerate(images):\n",
        "        image_np = image.numpy()[0, :, :]\n",
        "        variance = np.var(image_np)\n",
        "        if variance > 0.2:\n",
        "            flagged_indices.append(idx)\n",
        "    return flagged_indices\n",
        "\n",
        "\n",
        "# Preprocessing Functions\n",
        "def preprocess_images(dataset, flagged_indices):\n",
        "    new_dataset = []\n",
        "    for idx, (image, label) in enumerate(dataset):\n",
        "        if idx in flagged_indices:\n",
        "            image = torchvision.transforms.functional.gaussian_blur(image, kernel_size=(3, 3))\n",
        "        new_dataset.append((image, label))\n",
        "    return new_dataset\n",
        "\n",
        "\n",
        "def clean_labels(dataset, poisoned_indices):\n",
        "    new_dataset = []\n",
        "    for idx, (image, label) in enumerate(dataset):\n",
        "        if idx in poisoned_indices:\n",
        "            label = -1\n",
        "        new_dataset.append((image, label))\n",
        "    return new_dataset\n",
        "\n",
        "\n",
        "# Simulate Malicious Client Updates\n",
        "def simulate_malicious_client_update(global_model):\n",
        "    \"\"\"\n",
        "    Simulate a malicious client by submitting random updates.\n",
        "    \"\"\"\n",
        "    malicious_model = copy.deepcopy(global_model)\n",
        "    for param in malicious_model.parameters():\n",
        "        param.data = torch.rand_like(param)  # Randomized parameters\n",
        "    return malicious_model\n",
        "\n",
        "\n",
        "# Detect Malicious Clients\n",
        "def detect_malicious_clients(global_model, client_models, threshold=2.0):\n",
        "    \"\"\"\n",
        "    Detect malicious clients using L2 norm outlier detection.\n",
        "    \"\"\"\n",
        "    global_state = global_model.state_dict()\n",
        "    distances = []\n",
        "\n",
        "    for client_model in client_models:\n",
        "        if client_model is None:\n",
        "            distances.append(float('inf'))  # Assign a large distance for safety\n",
        "            continue\n",
        "\n",
        "        client_state = client_model.state_dict()\n",
        "        dist = sum(\n",
        "            (torch.norm(global_state[key] - client_state[key]).item())\n",
        "            for key in global_state.keys()\n",
        "        )\n",
        "        distances.append(dist)\n",
        "\n",
        "    mean_dist = np.mean(distances)\n",
        "    std_dist = np.std(distances)\n",
        "\n",
        "    if std_dist == 0:  # Handle case where all distances are identical\n",
        "        std_dist = 1e-6  # Avoid division by zero\n",
        "\n",
        "    # Flag clients with distances greater than mean + threshold * std\n",
        "    malicious_clients = [\n",
        "        idx for idx, dist in enumerate(distances) if dist > mean_dist + threshold * std_dist\n",
        "    ]\n",
        "    return malicious_clients\n",
        "\n",
        "\n",
        "# Aggregate Models\n",
        "def server_aggregate(global_model, client_models, malicious_clients):\n",
        "    \"\"\"\n",
        "    Aggregate model weights from clients into the global model, excluding malicious clients.\n",
        "    \"\"\"\n",
        "    global_state = global_model.state_dict()\n",
        "    valid_states = [\n",
        "        client_model.state_dict()\n",
        "        for idx, client_model in enumerate(client_models)\n",
        "        if idx not in malicious_clients and client_model is not None\n",
        "    ]\n",
        "\n",
        "    for k in global_state.keys():\n",
        "        client_updates = torch.stack([state[k] for state in valid_states], dim=0)\n",
        "        global_state[k] = torch.mean(client_updates, dim=0)\n",
        "\n",
        "    global_model.load_state_dict(global_state)\n",
        "\n",
        "\n",
        "# Federated Learning\n",
        "def federated_learning(n_clients, global_epochs, local_epochs, malicious_client_idx, attack_start_round):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset, test_dataset = load_data(transform)\n",
        "    client_datasets = partition_dataset(train_dataset, n_clients)\n",
        "    client_loaders = [DataLoader(dataset, batch_size=64, shuffle=True) for dataset in client_datasets]\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "    global_model = ConvNet().to(device)\n",
        "    client_models = [copy.deepcopy(global_model) for _ in range(n_clients)]\n",
        "    optimizers = [torch.optim.Adam(client_model.parameters(), lr=0.001) for client_model in client_models]\n",
        "\n",
        "    for global_epoch in range(global_epochs):\n",
        "        print(f\"Global Epoch {global_epoch + 1}/{global_epochs}\")\n",
        "\n",
        "        for client_idx in range(n_clients):\n",
        "            if global_epoch >= attack_start_round and client_idx == malicious_client_idx:\n",
        "                client_models[client_idx] = simulate_malicious_client_update(global_model)\n",
        "            else:\n",
        "                # Train each client's model\n",
        "                for data, labels in client_loaders[client_idx]:\n",
        "                    data, labels = data.to(device), labels.to(device)\n",
        "                    optimizer = optimizers[client_idx]\n",
        "                    optimizer.zero_grad()\n",
        "                    output = client_models[client_idx](data)\n",
        "                    loss = F.cross_entropy(output, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "        # Detect and mitigate malicious clients\n",
        "        malicious_clients = detect_malicious_clients(global_model, client_models)\n",
        "        print(f\"Malicious clients detected: {malicious_clients}\")\n",
        "\n",
        "        server_aggregate(global_model, client_models, malicious_clients)\n",
        "\n",
        "        # Evaluate the global model\n",
        "        accuracy = evaluate_model(global_model, test_loader, device)\n",
        "        print(f\"Test Accuracy after round {global_epoch + 1}: {accuracy:.2f}%\")\n",
        "\n",
        "    torch.save(global_model.state_dict(), \"robust_federated_model.pth\")\n",
        "\n",
        "\n",
        "# Model Evaluation\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data, labels in test_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "# Main Function\n",
        "if __name__ == \"__main__\":\n",
        "    federated_learning(\n",
        "        n_clients=10, global_epochs=10, local_epochs=2, malicious_client_idx=7, attack_start_round=5\n",
        "    )\n",
        "\n",
        "\n"
      ]
    }
  ]
}