{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG6CImy7B1CI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Load MNIST Dataset\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load and preprocess MNIST dataset with normalization and augmentation.\n",
        "\n",
        "    Returns:\n",
        "    train_loader: DataLoader for training\n",
        "    test_loader: DataLoader for testing\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize to ResNet50's input size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),  # Normalize for grayscale images\n",
        "    ])\n",
        "\n",
        "    train_dataset = torchvision.datasets.MNIST(\n",
        "        root='./data', train=True, download=True, transform=transform\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.MNIST(\n",
        "        root='./data', train=False, download=True, transform=transform\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    print(\"Training samples:\", len(train_dataset))\n",
        "    print(\"Testing samples:\", len(test_dataset))\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# 2. Modify ResNet50 for MNIST\n",
        "def get_model():\n",
        "    \"\"\"\n",
        "    Load and modify ResNet50 for MNIST classification.\n",
        "\n",
        "    Returns:\n",
        "    model: ResNet50 model adapted for MNIST\n",
        "    \"\"\"\n",
        "    model = resnet50(weights=ResNet50_Weights.DEFAULT)  # Load pretrained ResNet50\n",
        "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Adjust for single-channel input\n",
        "    model.fc = nn.Linear(model.fc.in_features, 10)  # Adjust final layer for 10 classes\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "# 3. Training Function\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=20):\n",
        "    \"\"\"\n",
        "    Train the model and apply SWA for better generalization.\n",
        "\n",
        "    Args:\n",
        "    model: Neural network model\n",
        "    train_loader: DataLoader for training\n",
        "    test_loader: DataLoader for testing\n",
        "    criterion: Loss function\n",
        "    optimizer: Optimizer\n",
        "    scheduler: Learning rate scheduler\n",
        "    num_epochs: Number of epochs to train\n",
        "\n",
        "    Returns:\n",
        "    best_accuracy: Best test accuracy achieved\n",
        "    \"\"\"\n",
        "    best_accuracy = 0.0\n",
        "    swa_model = AveragedModel(model)  # Initialize SWA model\n",
        "    swa_start = int(0.75 * num_epochs)  # SWA starts at 75% of total epochs\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Ensure inputs and labels are on the same device\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagation and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accuracy tracking\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Update SWA model\n",
        "        if epoch >= swa_start:\n",
        "            swa_model.update_parameters(model)\n",
        "\n",
        "        # Validation accuracy\n",
        "        val_accuracy = evaluate_model(model, test_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {100*correct/total:.2f}%, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"Best model saved with accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "    # Apply SWA BatchNorm updates and save SWA model\n",
        "    torch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n",
        "    torch.save(swa_model.state_dict(), 'swa_best_model.pth')\n",
        "    return best_accuracy\n",
        "\n",
        "# 4. Evaluation Function\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test dataset.\n",
        "\n",
        "    Args:\n",
        "    model: Trained model\n",
        "    test_loader: DataLoader for testing\n",
        "\n",
        "    Returns:\n",
        "    accuracy: Test accuracy\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to train, save, and evaluate the MNIST classification model.\n",
        "    \"\"\"\n",
        "    train_loader, test_loader = load_data()  # Load MNIST data\n",
        "    model = get_model()  # Load and modify ResNet50\n",
        "\n",
        "    # Define loss function, optimizer, and learning rate scheduler\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)  # AdamW optimizer\n",
        "    scheduler = SWALR(optimizer, swa_lr=0.0005)  # Learning rate scheduler for SWA\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=20)\n",
        "\n",
        "    print(\"Evaluating best SWA model...\")\n",
        "    swa_model = AveragedModel(model)\n",
        "    swa_model.load_state_dict(torch.load('swa_best_model.pth'))\n",
        "    swa_model = swa_model.to(device)\n",
        "    final_accuracy = evaluate_model(swa_model, test_loader)\n",
        "    print(f\"Final Test Accuracy: {final_accuracy:.2f}%\")\n",
        "\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}
